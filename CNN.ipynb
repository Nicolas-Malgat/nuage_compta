{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.12 64-bit ('deep-learning': conda)",
   "metadata": {
    "interpreter": {
     "hash": "4fe2c7d8583915c62953c6af93dcc06775348c3b267ab901cb91daee53dc2af3"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Adaptation du tutoriel vers le texte"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import floor\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randrange\n",
    "\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from modules.loader import ComptaDataLoader\n",
    "\n",
    "print('env: ', os.environ['CONDA_DEFAULT_ENV'])\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "source": [
    "## Téléchargement des données"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = ComptaDataLoader()\n",
    "loader.ensure_data_loaded()"
   ]
  },
  {
   "source": [
    "## Creation d'un CSV"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = ComptaDataLoader()\n",
    "loader.create_csv(100)"
   ]
  },
  {
   "source": [
    "## Lecture des csv"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"../datas/CURATED/\"\n",
    "\n",
    "data = np.genfromtxt(path + '100_data.csv', delimiter=',')\n",
    "labels = np.genfromtxt(path + '100_labels.csv', delimiter=',')\n"
   ]
  },
  {
   "source": [
    "## Preprocessing d'image"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explication:\n",
    "# 0     127.5   255   3 valeurs par defaut\n",
    "# 0     .25     1     /255\n",
    "# -.5   0       .5    -.5\n",
    "data = (data / 255) - 0.5\n",
    "\n",
    "data = np.apply_along_axis(lambda row: row.reshape(28,28), 1, data)\n",
    "data = np.expand_dims(data, axis=3)\n",
    "\n",
    "labels = to_categorical(labels)\n",
    "\n",
    "# Mélange de manière synchronisé la data et les labels\n",
    "randomize = np.arange(len(data))\n",
    "np.random.shuffle(randomize)\n",
    "data = data[randomize]\n",
    "labels = labels[randomize]\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "datagen.fit(data)\n",
    "\n",
    "\n",
    "print(\n",
    "    data.shape, '\\n',\n",
    "    labels.shape, '\\n',\n",
    "    [np.argmax(row) for row in labels[:10]]\n",
    ")"
   ]
  },
  {
   "source": [
    "## Je plot une lettre:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_random = randrange(0, len(data))\n",
    "\n",
    "img = data[nb_random]\n",
    "plt.imshow(img, cmap='Greys')\n",
    "print( \"C'est un \" + loader.int_to_letter(np.argmax(labels[nb_random])))\n",
    "\n",
    "del(img, nb_random)"
   ]
  },
  {
   "source": [
    "## Construction du modèle"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "  layers.Conv2D(28, 3, activation='relu'),\n",
    "  layers.Conv2D(56, 3, activation='relu'),\n",
    "  layers.MaxPooling2D(2, 2),\n",
    "  layers.Dropout(0.25),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dropout(0.5),\n",
    "  layers.Dense(26, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "  'adam',\n",
    "  loss='categorical_crossentropy',\n",
    "  metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "source": [
    "## Entrainement du modèle"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "  data,\n",
    "  labels,\n",
    "  epochs=20,\n",
    "  validation_split=0.25,\n",
    "  verbose=2\n",
    ")\n",
    "\n",
    "model.save(str(int(len(data)/26)) + '_CNN.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_to_letter(index: int):\n",
    "    alphabet = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n",
    "    return alphabet[index]\n",
    "\n",
    "# from keras.models import load_model\n",
    "# model = load_model('1000_CNN.h5')\n",
    "\n",
    "nb_element = 29\n",
    "nb_random = randrange(0, len(data)-nb_element)\n",
    "\n",
    "\n",
    "prediction = [ transform_to_letter(lettre) for lettre in np.argmax(model.predict(data[nb_random:nb_random+nb_element]) , axis=1)]\n",
    "verite = [ transform_to_letter(np.argmax(lettre))  for lettre in labels[nb_random:nb_random+nb_element] ] \n",
    "\n",
    "print(\n",
    "    'Prediciton:\\t', prediction,\n",
    "    '\\nVérité:\\t\\t', verite,\n",
    "    '\\nLe modèle donne un resultat juste ? ', prediction == verite\n",
    ")"
   ]
  },
  {
   "source": [
    "# Les hyperparamètres à tester:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Network Depth\n",
    "What happens if we add or remove Convolutional layers? How does that affect training and/or the model’s final performance?\n",
    "```\n",
    "model = Sequential([\n",
    "  Conv2D(num_filters, filter_size, input_shape=(28, 28, 1)),\n",
    "\n",
    "  Conv2D(num_filters, filter_size),\n",
    "  \n",
    "  MaxPooling2D(pool_size=pool_size),\n",
    "  Flatten(),\n",
    "  Dense(10, activation='softmax'),\n",
    "])\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Dropout\n",
    "What if we tried adding Dropout layers, which are commonly used to prevent overfitting (surentrainement) ?\n",
    "```\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "model = Sequential([\n",
    "  Conv2D(num_filters, filter_size, input_shape=(28, 28, 1)),\n",
    "  MaxPooling2D(pool_size=pool_size),\n",
    "  \n",
    "  Dropout(0.5),\n",
    "\n",
    "  Flatten(),\n",
    "  Dense(10, activation='softmax'),\n",
    "])\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Fully-connected Layers\n",
    "What if we add fully-connected layers between the Convolutional outputs and the final Softmax layer? This is something commonly done in CNNs used for Computer Vision.\n",
    "\n",
    "```\n",
    "model = Sequential([\n",
    "  Conv2D(num_filters, filter_size, input_shape=(28, 28, 1)),\n",
    "  MaxPooling2D(pool_size=pool_size),\n",
    "  Flatten(),\n",
    "\n",
    "  Dense(64, activation='relu'),\n",
    "  \n",
    "  Dense(10, activation='softmax'),\n",
    "])\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Convolution Parameters\n",
    "\n",
    "What if we play with the Conv2D parameters? For example:\n",
    "\n",
    "```\n",
    "Conv2D(\n",
    "    num_filters,\n",
    "    filter_size,\n",
    "    input_shape=(28, 28, 1),\n",
    "\n",
    "    strides=2,\n",
    "    padding='same',\n",
    "    activation='relu',\n",
    "    \n",
    "  ),\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "code complet du tutoriel :\n",
    "\n",
    "``` python\n",
    "# The full CNN code!\n",
    "####################\n",
    "import numpy as np\n",
    "import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "train_images = mnist.train_images()\n",
    "train_labels = mnist.train_labels()\n",
    "test_images = mnist.test_images()\n",
    "test_labels = mnist.test_labels()\n",
    "\n",
    "# Normalize the images.\n",
    "train_images = (train_images / 255) - 0.5\n",
    "test_images = (test_images / 255) - 0.5\n",
    "\n",
    "# Reshape the images.\n",
    "train_images = np.expand_dims(train_images, axis=3)\n",
    "test_images = np.expand_dims(test_images, axis=3)\n",
    "\n",
    "num_filters = 8\n",
    "filter_size = 3\n",
    "pool_size = 2\n",
    "\n",
    "# Build the model.\n",
    "model = Sequential([\n",
    "  Conv2D(num_filters, filter_size, input_shape=(28, 28, 1)),\n",
    "  MaxPooling2D(pool_size=pool_size),\n",
    "  Flatten(),\n",
    "  Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "# Compile the model.\n",
    "model.compile(\n",
    "  'adam',\n",
    "  loss='categorical_crossentropy',\n",
    "  metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "# Train the model.\n",
    "model.fit(\n",
    "  train_images,\n",
    "  to_categorical(train_labels),\n",
    "  epochs=3,\n",
    "  validation_data=(test_images, to_categorical(test_labels)),\n",
    ")\n",
    "\n",
    "# Save the model to disk.\n",
    "model.save_weights('cnn.h5')\n",
    "\n",
    "# Load the model from disk later using:\n",
    "# model.load_weights('cnn.h5')\n",
    "\n",
    "# Predict on the first 5 test images.\n",
    "predictions = model.predict(test_images[:5])\n",
    "\n",
    "# Print our model's predictions.\n",
    "print(np.argmax(predictions, axis=1)) # [7, 2, 1, 0, 4]\n",
    "\n",
    "# Check our predictions against the ground truths.\n",
    "print(test_labels[:5]) # [7, 2, 1, 0, 4]\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}